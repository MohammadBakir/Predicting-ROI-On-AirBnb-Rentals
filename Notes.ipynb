{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Notes\n",
    "\n",
    "-Initial Transformation:\n",
    "    Log Based 10 and Square Root of the ROI\n",
    "\n",
    "-Secondary Transformation:\n",
    "    Log Based 10 of \n",
    "        Number of Accomodations\n",
    "        data_accom = np.log(airbnb_numeric_only_1_o_3['accommodates'])\n",
    "    \n",
    "        Number of Bathrooms\n",
    "        data_bath = np.log(airbnb_numeric_only_1_o_3['bathrooms']+1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    One Hot Encode\n",
    "        Potentially - Number of Bedrooms\n",
    "        \n",
    "Elastic Net\n",
    "Lambda\n",
    "Residual amd plot\n",
    "Q-Q plot to verify Normal\n",
    "\n",
    "\n",
    "\n",
    "--------------------------\n",
    "\n",
    "\n",
    "Learning the parameters of a prediction function and testing it on the same data is a \n",
    "methodological mistake: a model that would just repeat the labels of the samples that \n",
    "it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data.\n",
    "\n",
    "When evaluating different settings (“hyperparameters”) for estimators, there is still a risk of overfitting \n",
    "on the test set because the parameters can be tweaked until the estimator performs optimally. \n",
    "\n",
    "This way, knowledge about the test set can “leak” into the model and evaluation metrics no longer report on \n",
    "generalization performance\n",
    "\n",
    "A model is trained using  of the folds as training data;\n",
    "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a \n",
    "performance measure such as accuracy).\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop.\n",
    "\n",
    "Mean Absolute Error a risk metric corresponding to the expected value of the absolute error loss or -norm loss.\n",
    "It measures the average magnitude of the errors in a set of predictions, without considering their direction.\n",
    "It measures a difference between two continous variables\n",
    "\n",
    "It provides a measure of how well future samples are likely to be predicted by the model. Best possible score \n",
    "is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts \n",
    "the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "\n",
    "\n",
    "Standardize\n",
    "Generalization -> Elastic Net Grid Search ->Reduce Complexity ->Regularize on test, which ones are resilient,\n",
    "\n",
    "Semantics, Run a Ridge, \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
